{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D image matching with LDDMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion() # for drawing in real time\n",
    "import nibabel as nib\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load images to register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image filenames here\n",
    "# we will deform the atlas to match the target\n",
    "atlas_image_fname = 'Adt27-55_02_Adt27-55_02_MNI.img'\n",
    "target_image_fname = 'Adt27-55_03_Adt27-55_03_MNI.img'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load them\n",
    "fnames = [atlas_image_fname,target_image_fname]\n",
    "img = [nib.load(fname) for fname in fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get info about domains\n",
    "# we assume for this example that we have the same voxel size and same voxel spacing\n",
    "if '.img' == atlas_image_fname[-4:]:    \n",
    "    nx = img[0].header['dim'][1:4]\n",
    "    dx = img[0].header['pixdim'][1:4]\n",
    "else:\n",
    "    # I'm only working with analyze for now\n",
    "    raise ValueError('Only Analyze images supported for now')\n",
    "x = [np.arange(nxi)*dxi for nxi,dxi in zip(nx,dx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the images, note they also include a fourth axis for time that I don't want\n",
    "I = img[0].get_data()[:,:,:,0]\n",
    "J = img[1].get_data()[:,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple function for drawing 3 slices\n",
    "def draw_slices(x,I,axlist,**kwargs):\n",
    "    ''' Draw three slices through the middle of an image'''\n",
    "    axlist[0].imshow(np.squeeze(I[:,:,I.shape[2]//2]),**kwargs)\n",
    "    axlist[1].imshow(np.squeeze(I[:,I.shape[1]//2,:]),**kwargs)\n",
    "    axlist[2].imshow(np.squeeze(I[I.shape[0]//2,:,:]),**kwargs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw my images\n",
    "f,ax = plt.subplots(2,3)\n",
    "draw_slices(x,I,ax[0],aspect='equal',cmap='gray')\n",
    "draw_slices(x,J,ax[1],aspect='equal',cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we need to define a linear interpolation function in tensorflow for 3d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp3(x0,x1,x2,I,phi0,phi1,phi2):\n",
    "    ''' \n",
    "    Linear interpolation\n",
    "    Interpolate a 3D tensorflow image I\n",
    "    with voxels corresponding to locations in x0, x1 (1d arrays)\n",
    "    at the points phi0, phi1 (2d arrays)\n",
    "    '''\n",
    "    # get the size\n",
    "    dx = [x0[1]-x0[0], x1[1]-x1[0], x2[1]-x2[0]]\n",
    "    nx = [len(x0), len(x1), len(x2)]\n",
    "    #convert to index\n",
    "    phi0_index = (phi0 - x0[0])/dx[0]\n",
    "    phi1_index = (phi1 - x1[0])/dx[1]\n",
    "    phi2_index = (phi2 - x2[0])/dx[2]\n",
    "    # take the floor to get integers\n",
    "    phi0_index_floor = tf.floor(phi0_index)\n",
    "    phi1_index_floor = tf.floor(phi1_index)\n",
    "    phi2_index_floor = tf.floor(phi2_index)\n",
    "    # get the fraction to the next pixel\n",
    "    phi0_p = phi0_index - phi0_index_floor\n",
    "    phi1_p = phi1_index - phi1_index_floor\n",
    "    phi2_p = phi2_index - phi2_index_floor\n",
    "    # get the next samples\n",
    "    phi0_index_floor_1 = phi0_index_floor+1\n",
    "    phi1_index_floor_1 = phi1_index_floor+1\n",
    "    phi2_index_floor_1 = phi2_index_floor+1\n",
    "    # and apply boundary conditions\n",
    "    phi0_index_floor = tf.minimum(phi0_index_floor,nx[0]-1)\n",
    "    phi0_index_floor = tf.maximum(phi0_index_floor,0)\n",
    "    phi0_index_floor_1 = tf.minimum(phi0_index_floor_1,nx[0]-1)\n",
    "    phi0_index_floor_1 = tf.maximum(phi0_index_floor_1,0)\n",
    "    phi1_index_floor = tf.minimum(phi1_index_floor,nx[1]-1)\n",
    "    phi1_index_floor = tf.maximum(phi1_index_floor,0)\n",
    "    phi1_index_floor_1 = tf.minimum(phi1_index_floor_1,nx[1]-1)\n",
    "    phi1_index_floor_1 = tf.maximum(phi1_index_floor_1,0)\n",
    "    phi2_index_floor = tf.minimum(phi2_index_floor,nx[2]-1)\n",
    "    phi2_index_floor = tf.maximum(phi2_index_floor,0)\n",
    "    phi2_index_floor_1 = tf.minimum(phi2_index_floor_1,nx[2]-1)\n",
    "    phi2_index_floor_1 = tf.maximum(phi2_index_floor_1,0)\n",
    "    # then we will need to vectorize everything to use scalar indices\n",
    "    phi0_index_floor_flat = tf.reshape(phi0_index_floor,[-1])\n",
    "    phi0_index_floor_flat_1 = tf.reshape(phi0_index_floor_1,[-1])\n",
    "    phi1_index_floor_flat = tf.reshape(phi1_index_floor,[-1])\n",
    "    phi1_index_floor_flat_1 = tf.reshape(phi1_index_floor_1,[-1])\n",
    "    phi2_index_floor_flat = tf.reshape(phi2_index_floor,[-1])\n",
    "    phi2_index_floor_flat_1 = tf.reshape(phi2_index_floor_1,[-1])\n",
    "    I_flat = tf.reshape(I,[-1])\n",
    "    # indices recall that the LAST INDEX IS CONTIGUOUS\n",
    "    phi_index_floor_flat_000 = nx[2]*nx[1]*phi0_index_floor_flat + nx[1]*phi1_index_floor_flat + phi2_index_floor_flat\n",
    "    phi_index_floor_flat_001 = nx[2]*nx[1]*phi0_index_floor_flat + nx[1]*phi1_index_floor_flat + phi2_index_floor_flat_1\n",
    "    phi_index_floor_flat_010 = nx[2]*nx[1]*phi0_index_floor_flat + nx[1]*phi1_index_floor_flat_1 + phi2_index_floor_flat\n",
    "    phi_index_floor_flat_011 = nx[2]*nx[1]*phi0_index_floor_flat + nx[1]*phi1_index_floor_flat_1 + phi2_index_floor_flat_1\n",
    "    phi_index_floor_flat_100 = nx[2]*nx[1]*phi0_index_floor_flat_1 + nx[1]*phi1_index_floor_flat + phi2_index_floor_flat\n",
    "    phi_index_floor_flat_101 = nx[2]*nx[1]*phi0_index_floor_flat_1 + nx[1]*phi1_index_floor_flat + phi2_index_floor_flat_1\n",
    "    phi_index_floor_flat_110 = nx[2]*nx[1]*phi0_index_floor_flat_1 + nx[1]*phi1_index_floor_flat_1 + phi2_index_floor_flat\n",
    "    phi_index_floor_flat_111 = nx[2]*nx[1]*phi0_index_floor_flat_1 + nx[1]*phi1_index_floor_flat_1 + phi2_index_floor_flat_1\n",
    "    \n",
    "    # now slice the image\n",
    "    I000_flat = tf.gather(I_flat, tf.cast(phi_index_floor_flat_000, dtype=tf.int64))\n",
    "    I001_flat = tf.gather(I_flat, tf.cast(phi_index_floor_flat_001, dtype=tf.int64))\n",
    "    I010_flat = tf.gather(I_flat, tf.cast(phi_index_floor_flat_010, dtype=tf.int64))\n",
    "    I011_flat = tf.gather(I_flat, tf.cast(phi_index_floor_flat_011, dtype=tf.int64))\n",
    "    I100_flat = tf.gather(I_flat, tf.cast(phi_index_floor_flat_100, dtype=tf.int64))\n",
    "    I101_flat = tf.gather(I_flat, tf.cast(phi_index_floor_flat_101, dtype=tf.int64))\n",
    "    I110_flat = tf.gather(I_flat, tf.cast(phi_index_floor_flat_110, dtype=tf.int64))\n",
    "    I111_flat = tf.gather(I_flat, tf.cast(phi_index_floor_flat_111, dtype=tf.int64))\n",
    "    \n",
    "    # reshape it\n",
    "    I000 = tf.reshape(I000_flat,nx)\n",
    "    I001 = tf.reshape(I001_flat,nx)\n",
    "    I010 = tf.reshape(I010_flat,nx)\n",
    "    I011 = tf.reshape(I011_flat,nx)\n",
    "    I100 = tf.reshape(I100_flat,nx)\n",
    "    I101 = tf.reshape(I101_flat,nx)\n",
    "    I110 = tf.reshape(I110_flat,nx)\n",
    "    I111 = tf.reshape(I111_flat,nx)\n",
    "\n",
    "    # combine them!\n",
    "    Il = I000*(1.0-phi0_p)*(1.0-phi1_p)*(1.0-phi2_p)\\\n",
    "        + I001*(1.0-phi0_p)*(1.0-phi1_p)*(    phi2_p)\\\n",
    "        + I010*(1.0-phi0_p)*(    phi1_p)*(1.0-phi2_p)\\\n",
    "        + I011*(1.0-phi0_p)*(    phi1_p)*(    phi2_p)\\\n",
    "        + I100*(    phi0_p)*(1.0-phi1_p)*(1.0-phi2_p)\\\n",
    "        + I101*(    phi0_p)*(1.0-phi1_p)*(    phi2_p)\\\n",
    "        + I110*(    phi0_p)*(    phi1_p)*(1.0-phi2_p)\\\n",
    "        + I111*(    phi0_p)*(    phi1_p)*(    phi2_p)\n",
    "    return Il"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## and we need a gradient function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad3(I,dx):\n",
    "    I_0 = (tf.manip.roll(I,shift=-1,axis=0) - tf.manip.roll(I,shift=1,axis=0))/2.0/dx[0]\n",
    "    I_1 = (tf.manip.roll(I,shift=-1,axis=1) - tf.manip.roll(I,shift=1,axis=1))/2.0/dx[1]\n",
    "    I_2 = (tf.manip.roll(I,shift=-1,axis=2) - tf.manip.roll(I,shift=1,axis=2))/2.0/dx[2]\n",
    "    \n",
    "    #out[0,:] = out[1,:]-out[0,:] # this doesn't work in tensorflow\n",
    "    # generally you cannot assign to a tensor\n",
    "    return I_0, I_1, I_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now we set some parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent stepsize this will be a placeholder\n",
    "# each time we will take a gradient descent step\n",
    "# we may want to change it from time to time\n",
    "epsilon = 1e-1\n",
    "epsilonph = tf.placeholder(tf.float32, shape=()) \n",
    "niter = 20 # number of optimization iterations\n",
    "\n",
    "# flow parameters\n",
    "nt = 5 # number of timesteps\n",
    "dt = 1.0/nt # increment in time for each step\n",
    "alpha = dx[0]*2.0 # spatial scale of smoothing operator\n",
    "power = 2.0 # power of identity - alpha*Laplacian\n",
    "\n",
    "# cost parameters\n",
    "sigmaM = (np.max(J) - np.min(J))*0.1 # matching cost standard deviation, smaller means larger cost\n",
    "sigmaM = 1e1\n",
    "sigmaR = 1e0 # regularization cost standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build a Fourier domain and differential operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = np.arange(nx[0])/dx[0]/nx[0]\n",
    "f1 = np.arange(nx[1])/dx[1]/nx[1]\n",
    "f2 = np.arange(nx[2])/dx[2]/nx[2]\n",
    "F0,F1,F2 = np.meshgrid(f0, f1, f2, indexing='ij')\n",
    "# identity minus laplacian, in fourier domain\n",
    "# AI[i,j] = I[i,j] - alpha^2( (I[i+1,j] - 2I[i,j] + I[i-1,j])/dx^2 + (I[i,j+1] - 2I[i,j] + I[i,j-1])/dy^2  )\n",
    "Lhat = (1.0 - alpha**2*((-2.0 + 2.0*np.cos(2*np.pi*dx[0]*F0))/dx[0]**2 \n",
    "    + (-2.0 + 2.0*np.cos(2*np.pi*dx[1]*F1))/dx[1]**2\n",
    "    + (-2.0 + 2.0*np.cos(2*np.pi*dx[2]*F2))/dx[2]**2))**power\n",
    "# for real ffts we only half of this, TODO\n",
    "LLhat = Lhat**2\n",
    "Khat = 1.0/LLhat\n",
    "# convert to tensorflow\n",
    "Khattf = tf.complex(tf.constant(Khat,dtype=tf.float32),0.)\n",
    "#LLhattf = tf.complex(tf.constant(LLhat,dtype=tf.float32),0.)\n",
    "LLhattf = tf.constant(LLhat,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize my optimization variables\n",
    "\n",
    "Each iteration there will be an old version and a new version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE this cell can only be run once\n",
    "# if you run it again it will generate errors\n",
    "vt0 = tf.get_variable('vt0',shape=[nx[0],nx[1],nx[2],nt],dtype=tf.float32,trainable=False,initializer=tf.zeros_initializer())\n",
    "vt1 = tf.get_variable('vt1',shape=[nx[0],nx[1],nx[2],nt],dtype=tf.float32,trainable=False,initializer=tf.zeros_initializer())\n",
    "vt2 = tf.get_variable('vt2',shape=[nx[0],nx[1],nx[2],nt],dtype=tf.float32,trainable=False,initializer=tf.zeros_initializer())\n",
    "\n",
    "vt0new = tf.get_variable('vt0new',shape=[nx[0],nx[1],nx[2],nt],dtype=tf.float32,trainable=False,initializer=tf.zeros_initializer())\n",
    "vt1new = tf.get_variable('vt1new',shape=[nx[0],nx[1],nx[2],nt],dtype=tf.float32,trainable=False,initializer=tf.zeros_initializer())\n",
    "vt2new = tf.get_variable('vt2new',shape=[nx[0],nx[1],nx[2],nt],dtype=tf.float32,trainable=False,initializer=tf.zeros_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the tensorflow graph for one iteration of gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize some variables\n",
    "Itf = tf.constant(I,dtype=tf.float32)\n",
    "Jtf = tf.constant(J,dtype=tf.float32)\n",
    "x0=x[0]\n",
    "x1=x[1]\n",
    "x2=x[2]\n",
    "X0,X1,X2 = np.meshgrid(x0,x1,x2,indexing='ij')\n",
    "X0tf = tf.constant(X0,dtype=tf.float32)\n",
    "X1tf = tf.constant(X1,dtype=tf.float32)\n",
    "X2tf = tf.constant(X2,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow forwards\n",
    "It = [Itf]\n",
    "phiinv0 = X0tf\n",
    "phiinv1 = X1tf\n",
    "phiinv2 = X2tf\n",
    "ER = 0\n",
    "for t in range(nt):\n",
    "    v0 = vt0[:,:,:,t]\n",
    "    v1 = vt1[:,:,:,t]\n",
    "    v2 = vt2[:,:,:,t]\n",
    "    X0s = X0 - v0*dt\n",
    "    X1s = X1 - v1*dt\n",
    "    X2s = X2 - v2*dt\n",
    "    \n",
    "    # update diffeomorphism with nice boundary conditions\n",
    "    phiinv0 = interp3(x0,x1,x2,phiinv0-X0tf,X0s,X1s,X2s)+X0s\n",
    "    phiinv1 = interp3(x0,x1,x2,phiinv1-X1tf,X0s,X1s,X2s)+X1s\n",
    "    phiinv2 = interp3(x0,x1,x2,phiinv2-X2tf,X0s,X1s,X2s)+X2s\n",
    "    \n",
    "    # deform the image\n",
    "    It.append(interp3(x0,x1,x2,Itf,phiinv0,phiinv1,phiinv2))\n",
    "    \n",
    "    # get regularization energy\n",
    "    # this is probably the fastest way to compute energy, note the normalizer 1/(number of elemetns)\n",
    "    v0hat = tf.fft2d(tf.cast(v0,tf.complex64))\n",
    "    v1hat = tf.fft2d(tf.cast(v1,tf.complex64))\n",
    "    v2hat = tf.fft2d(tf.cast(v2,tf.complex64))\n",
    "    ER = ER + tf.reduce_sum( ( tf.abs(v0hat)**2 + tf.abs(v1hat)**2 + tf.abs(v2hat)**2 ) * LLhattf )\n",
    "ER = ER*dt*dx[0]*dx[1]*dx[2]/sigmaR**2/2.0/nx[0]/nx[1]/nx[2]\n",
    "\n",
    "# now compute the error\n",
    "lambda1 = (It[-1] - J)/sigmaM**2\n",
    "\n",
    "# get matching energy \n",
    "EM = tf.reduce_sum((It[-1] - J)**2)/sigmaM**2*dx[0]*dx[1]*dx[2]/2.0\n",
    "E = EM + ER\n",
    "\n",
    "# flow the error backwards\n",
    "phiinv0 = X0tf\n",
    "phiinv1 = X1tf\n",
    "phiinv2 = X2tf\n",
    "vt0new_ = []\n",
    "vt1new_ = []\n",
    "vt2new_ = []\n",
    "for t in range(nt-1,-1,-1):\n",
    "    v0 = vt0[:,:,:,t]\n",
    "    v1 = vt1[:,:,:,t]\n",
    "    v2 = vt2[:,:,:,t]\n",
    "    X0s = X0 + v0*dt\n",
    "    X1s = X1 + v1*dt\n",
    "    X2s = X2 + v2*dt\n",
    "    phiinv0 = interp3(x0,x1,x2,phiinv0-X0tf,X0s,X1s,X2s) + X0s\n",
    "    phiinv1 = interp3(x0,x1,x2,phiinv1-X1tf,X0s,X1s,X2s) + X1s\n",
    "    phiinv2 = interp3(x0,x1,x2,phiinv2-X2tf,X0s,X1s,X2s) + X2s\n",
    "    \n",
    "    # compute the gradient of the image at this time\n",
    "    I_0,I_1,I_2 = grad3(It[t],dx)\n",
    "    \n",
    "    # compute the determinanat of jacobian\n",
    "    phiinv0_0,phiinv0_1,phiinv0_2 = grad3(phiinv0,dx)\n",
    "    phiinv1_0,phiinv1_1,phiinv1_2 = grad3(phiinv1,dx)\n",
    "    phiinv2_0,phiinv2_1,phiinv2_2 = grad3(phiinv2,dx)\n",
    "    detjac = phiinv0_0*(phiinv1_1*phiinv2_2 - phiinv1_2*phiinv2_1)\\\n",
    "        - phiinv0_1*(phiinv1_0*phiinv2_2 - phiinv1_2*phiinv2_0)\\\n",
    "        + phiinv0_2*(phiinv1_0*phiinv2_1 - phiinv1_1*phiinv2_0)\n",
    "    \n",
    "    # get the lambda for this time\n",
    "    lambda_ = interp3(x0,x1,x2,lambda1,phiinv0,phiinv1,phiinv2)*detjac\n",
    "    \n",
    "    # set up the gradient\n",
    "    grad0 = -lambda_*I_0\n",
    "    grad1 = -lambda_*I_1\n",
    "    grad2 = -lambda_*I_2\n",
    "    \n",
    "    # smooth it\n",
    "    grad0 = tf.real(tf.ifft2d(tf.fft2d(tf.cast(grad0,tf.complex64))*Khattf))\n",
    "    grad1 = tf.real(tf.ifft2d(tf.fft2d(tf.cast(grad1,tf.complex64))*Khattf))\n",
    "    grad2 = tf.real(tf.ifft2d(tf.fft2d(tf.cast(grad2,tf.complex64))*Khattf))\n",
    "    \n",
    "    # add the regularization\n",
    "    grad0 = grad0 + v0/sigmaR**2\n",
    "    grad1 = grad1 + v1/sigmaR**2\n",
    "    grad2 = grad2 + v2/sigmaR**2\n",
    "    \n",
    "    # and calculate the new v\n",
    "    vt0new_.append(v0 - epsilonph*grad0)\n",
    "    vt1new_.append(v1 - epsilonph*grad1)\n",
    "    vt2new_.append(v2 - epsilonph*grad2)\n",
    "\n",
    "# stack\n",
    "vt0new = tf.stack(vt0new_[::-1],axis=3)\n",
    "vt1new = tf.stack(vt1new_[::-1],axis=3)\n",
    "vt2new = tf.stack(vt2new_[::-1],axis=3)\n",
    "\n",
    "# define a graph operation\n",
    "step = tf.group(\n",
    "  vt0.assign(vt0new),\n",
    "  vt1.assign(vt1new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMall = []\n",
    "ERall = []\n",
    "Eall = []\n",
    "f,ax = plt.subplots(2,2)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(niter):\n",
    "        # take a step of gradient descent\n",
    "        step.run({epsilonph:epsilon})\n",
    "        \n",
    "        Idnp = It[-1].eval()\n",
    "        ax[0][0].imshow(Idnp,**imopts)\n",
    "        ax[0][0].set_title('deformed image'.format(i))\n",
    "        \n",
    "        lambda1np = lambda1.eval()\n",
    "        ax[0][1].imshow(lambda1np,**imopts)\n",
    "        ax[0][1].set_title('error')\n",
    "        \n",
    "        EMall.append(EM.eval())\n",
    "        ERall.append(ER.eval())\n",
    "        Eall.append(E.eval())\n",
    "        ax[1][0].cla()\n",
    "        ax[1][0].plot(list(zip(Eall,EMall,ERall)))\n",
    "        xlim = ax[1][0].get_xlim()\n",
    "        ylim = ax[1][0].get_ylim()\n",
    "        ax[1][0].set_aspect((xlim[1]-xlim[0])/(ylim[1]-ylim[0]))\n",
    "        ax[1][0].legend(['Etot','Ematch','Ereg'])\n",
    "        \n",
    "        ax[1][1].imshow(J,**imopts)\n",
    "        \n",
    "        f.canvas.draw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
