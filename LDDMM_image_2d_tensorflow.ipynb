{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D Image matching LDDMM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion() # for drawing in real time\n",
    "import nibabel as nib\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load images to register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image filenames here\n",
    "# we will deform the atlas to match the target\n",
    "atlas_image_fname = 'Adt27-55_02_Adt27-55_02_MNI.img'\n",
    "target_image_fname = 'Adt27-55_03_Adt27-55_03_MNI.img'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load them\n",
    "fnames = [atlas_image_fname,target_image_fname]\n",
    "img = [nib.load(fname) for fname in fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get info about domains\n",
    "# we assume for this example that we have the same voxel size and same voxel spacing\n",
    "if '.img' == atlas_image_fname[-4:]:    \n",
    "    nx = img[0].header['dim'][1:3]\n",
    "    dx = img[0].header['pixdim'][1:3]\n",
    "else:\n",
    "    # I'm only working with analyze for now\n",
    "    raise ValueError('Only Analyze images supported for now')\n",
    "x = [np.arange(nxi)*dxi for nxi,dxi in zip(nx,dx)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 2D slices for this example\n",
    "s = int(img[0].shape[2]/2*0.96)\n",
    "I,J = [i.get_data()[:,:,s,0] for i in img]\n",
    "f,ax = plt.subplots(1,2,sharex=True,sharey=True)\n",
    "imopts = {'cmap':'gray','extent':(x[1][0],x[1][-1],x[0][0],x[0][-1]), 'aspect':'equal'}\n",
    "ax[0].imshow(I,**imopts)\n",
    "ax[1].imshow(J,**imopts)\n",
    "for i,a in enumerate(ax):\n",
    "    a.set_xlabel('x (mm)')\n",
    "    a.set_ylabel('y (mm)')\n",
    "    a.set_title('Image {}'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we need to define a linear interpolation function in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp2(x0,x1,Itf,phi0tf,phi1tf):\n",
    "    ''' \n",
    "    Linear interpolation\n",
    "    Interpolate a 2D tensorflow image Itf\n",
    "    with voxels corresponding to locations in x0, x1 (1d arrays)\n",
    "    at the points phi0tf, phi1tf (2d arrays)\n",
    "    '''\n",
    "    # get the size\n",
    "    dx = [x0[1]-x0[0], x1[1]-x1[0]]\n",
    "    nx = [len(x0), len(x1)]    \n",
    "    #convert to index\n",
    "    phi0_index = (phi0tf - x0[0])/dx[0]\n",
    "    phi1_index = (phi1tf - x1[0])/dx[1]\n",
    "    # take the floor to get integers\n",
    "    phi0_index_floor = tf.floor(phi0_index)\n",
    "    phi1_index_floor = tf.floor(phi1_index)\n",
    "    # get the fraction to the next pixel\n",
    "    phi0_p = phi0_index - phi0_index_floor\n",
    "    phi1_p = phi1_index - phi1_index_floor\n",
    "    # get the next samples\n",
    "    phi0_index_floor_1 = phi0_index_floor+1\n",
    "    phi1_index_floor_1 = phi1_index_floor+1\n",
    "    # and apply boundary conditions\n",
    "    phi0_index_floor = tf.minimum(phi0_index_floor,nx[0]-1)\n",
    "    phi0_index_floor = tf.maximum(phi0_index_floor,0)\n",
    "    phi0_index_floor_1 = tf.minimum(phi0_index_floor_1,nx[0]-1)\n",
    "    phi0_index_floor_1 = tf.maximum(phi0_index_floor_1,0)\n",
    "    phi1_index_floor = tf.minimum(phi1_index_floor,nx[1]-1)\n",
    "    phi1_index_floor = tf.maximum(phi1_index_floor,0)\n",
    "    phi1_index_floor_1 = tf.minimum(phi1_index_floor_1,nx[1]-1)\n",
    "    phi1_index_floor_1 = tf.maximum(phi1_index_floor_1,0)\n",
    "    # then we will need to vectorize everything to use scalar indices\n",
    "    phi0_index_floor_flat = tf.reshape(phi0_index_floor,[-1])\n",
    "    phi0_index_floor_flat_1 = tf.reshape(phi0_index_floor_1,[-1])\n",
    "    phi1_index_floor_flat = tf.reshape(phi1_index_floor,[-1])\n",
    "    phi1_index_floor_flat_1 = tf.reshape(phi1_index_floor_1,[-1])\n",
    "    I_flat = tf.reshape(Itf,[-1])\n",
    "    # indices recall that the LAST INDEX IS CONTIGUOUS\n",
    "    phi_index_floor_flat_00 = nx[1]*phi0_index_floor_flat + phi1_index_floor_flat\n",
    "    phi_index_floor_flat_01 = nx[1]*phi0_index_floor_flat + phi1_index_floor_flat_1\n",
    "    phi_index_floor_flat_10 = nx[1]*phi0_index_floor_flat_1 + phi1_index_floor_flat\n",
    "    phi_index_floor_flat_11 = nx[1]*phi0_index_floor_flat_1 + phi1_index_floor_flat_1\n",
    "    # now slice the image\n",
    "    I00_flat = tf.gather(I_flat, tf.cast(phi_index_floor_flat_00, dtype=tf.int64))\n",
    "    I01_flat = tf.gather(I_flat, tf.cast(phi_index_floor_flat_01, dtype=tf.int64))\n",
    "    I10_flat = tf.gather(I_flat, tf.cast(phi_index_floor_flat_10, dtype=tf.int64))\n",
    "    I11_flat = tf.gather(I_flat, tf.cast(phi_index_floor_flat_11, dtype=tf.int64))\n",
    "    # reshape it\n",
    "    I00 = tf.reshape(I00_flat,nx[:2])\n",
    "    I01 = tf.reshape(I01_flat,nx[:2])\n",
    "    I10 = tf.reshape(I10_flat,nx[:2])\n",
    "    I11 = tf.reshape(I11_flat,nx[:2])\n",
    "    # combine them!\n",
    "    Il = I00*(1.0-phi0_p)*(1.0-phi1_p) \\\n",
    "        + I01*(1.0-phi0_p)*(    phi1_p) \\\n",
    "        + I10*(    phi0_p)*(1.0-phi1_p) \\\n",
    "        + I11*(    phi0_p)*(    phi1_p)\n",
    "    return Il"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## and we need a gradient function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad2(Itf,dx):\n",
    "    I_0 = (tf.manip.roll(Itf,shift=-1,axis=0) - tf.manip.roll(Itf,shift=1,axis=0))/2.0/dx[0]\n",
    "    I_1 = (tf.manip.roll(Itf,shift=-1,axis=1) - tf.manip.roll(Itf,shift=1,axis=1))/2.0/dx[1]\n",
    "    #out[0,:] = out[1,:]-out[0,:] # this doesn't work in tensorflow\n",
    "    # generally you cannot assign to a tensor\n",
    "    return I_0, I_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we set some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent stepsize this will be a placeholder\n",
    "# each time we will take a gradient descent step\n",
    "# we may want to change it from time to time\n",
    "epsilon = 1e-1\n",
    "epsilonph = tf.placeholder(tf.float32, shape=()) \n",
    "niter = 10 # number of optimization iterations\n",
    "\n",
    "# flow parameters\n",
    "nt = 5 # number of timesteps\n",
    "dt = 1.0/nt # increment in time for each step\n",
    "alpha = dx[0]*2.0 # spatial scale of smoothing operator\n",
    "power = 2.0 # power of identity - alpha*Laplacian\n",
    "\n",
    "# cost parameters\n",
    "sigmaM = (np.max(J) - np.min(J))*0.1 # matching cost standard deviation\n",
    "sigmaM = 1e1\n",
    "sigmaR = 1e2 # regularization cost standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build a fourier domain and differential operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = np.arange(nx[0])/dx[0]/nx[0]\n",
    "f1 = np.arange(nx[1])/dx[1]/nx[1]\n",
    "F0,F1 = np.meshgrid(f0, f1, indexing='ij')\n",
    "# identity minus laplacian, in fourier domain\n",
    "# AI[i,j] = I[i,j] - alpha^2( (I[i+1,j] - 2I[i,j] + I[i-1,j])/dx^2 + (I[i,j+1] - 2I[i,j] + I[i,j-1])/dy^2  )\n",
    "Lhat = (1.0 - alpha**2*((-2.0 + 2.0*np.cos(2*np.pi*dx[0]*F0))/dx[0]**2 \n",
    "    + (-2.0 + 2.0*np.cos(2*np.pi*dx[1]*F1))/dx[1]**2   ))**power\n",
    "# for real ffts we only half of this, TODO\n",
    "LLhat = Lhat**2\n",
    "Khat = 1.0/LLhat\n",
    "# convert to tensorflow\n",
    "Khattf = tf.complex(tf.constant(Khat,dtype=tf.float32),0.)\n",
    "#LLhattf = tf.complex(tf.constant(LLhat,dtype=tf.float32),0.)\n",
    "LLhattf = tf.constant(LLhat,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize my optimization variables\n",
    "Each iteration there will be an old version and a new versoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vt0 = tf.get_variable('vt0',shape=[nx[0],nx[1],nt],dtype=tf.float32,trainable=False,initializer=tf.zeros_initializer())\n",
    "vt1 = tf.get_variable('vt1',shape=[nx[0],nx[1],nt],dtype=tf.float32,trainable=False,initializer=tf.zeros_initializer())\n",
    "vt0new = tf.get_variable('vt0new',shape=[nx[0],nx[1],nt],dtype=tf.float32,trainable=False,initializer=tf.zeros_initializer())\n",
    "vt1new = tf.get_variable('vt1new',shape=[nx[0],nx[1],nt],dtype=tf.float32,trainable=False,initializer=tf.zeros_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the tensorflow graph for one iteration of gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize some variables\n",
    "Itf = tf.constant(I,dtype=tf.float32)\n",
    "Jtf = tf.constant(J,dtype=tf.float32)\n",
    "x0=x[0]\n",
    "x1=x[1]\n",
    "X0,X1 = np.meshgrid(x0,x1,indexing='ij')\n",
    "X0tf = tf.constant(X0,dtype=tf.float32)\n",
    "X1tf = tf.constant(X1,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow forwards\n",
    "It = [Itf]\n",
    "phiinv0 = X0tf\n",
    "phiinv1 = X1tf\n",
    "ER = 0\n",
    "for t in range(nt):\n",
    "    v0 = vt0[:,:,t]\n",
    "    v1 = vt1[:,:,t]\n",
    "    X0s = X0 - v0*dt\n",
    "    X1s = X1 - v1*dt\n",
    "    \n",
    "    # update diffeomorphism with nice boundary conditions\n",
    "    phiinv0 = interp2(x0,x1,phiinv0-X0tf,X0s,X1s)+X0s\n",
    "    phiinv1 = interp2(x0,x1,phiinv1-X1tf,X0s,X1s)+X1s\n",
    "    \n",
    "    # deform the image\n",
    "    It.append(interp2(x0,x1,Itf,phiinv0,phiinv1))\n",
    "    \n",
    "    # get regularization energy\n",
    "    # this is probably the fastest way to compute energy, note the normalizer 1/(number of elemetns)\n",
    "    v0hat = tf.fft2d(tf.cast(v0,tf.complex64))\n",
    "    v1hat = tf.fft2d(tf.cast(v1,tf.complex64))\n",
    "    ER = ER + tf.reduce_sum( ( tf.abs(v0hat)**2 + tf.abs(v1hat)**2 ) * LLhattf )\n",
    "ER = ER*dt*dx[0]*dx[1]/sigmaR**2/2.0/nx[0]/nx[1]\n",
    "\n",
    "# now compute the error\n",
    "lambda1 = (It[-1] - J)/sigmaM**2\n",
    "\n",
    "# get matching energy \n",
    "EM = tf.reduce_sum((It[-1] - J)**2)/sigmaM**2*dx[0]*dx[1]/2.0\n",
    "E = EM + ER\n",
    "\n",
    "# flow the error backwards\n",
    "phiinv0 = X0tf\n",
    "phiinv1 = X1tf\n",
    "vt0new_ = []\n",
    "vt1new_ = []\n",
    "for t in range(nt-1,-1,-1):\n",
    "    v0 = vt0[:,:,t]\n",
    "    v1 = vt1[:,:,t]\n",
    "    X0s = X0 + v0*dt\n",
    "    X1s = X1 + v1*dt\n",
    "    phiinv0 = interp2(x0,x1,phiinv0-X0,X0s,X1s) + X0s\n",
    "    phiinv1 = interp2(x0,x1,phiinv1-X1,X0s,X1s) + X1s\n",
    "    \n",
    "    # compute the gradient of the image at this time\n",
    "    I_0,I_1 = grad2(It[t],dx)\n",
    "    \n",
    "    # compute the determinanat of jacobian\n",
    "    phiinv0_0,phiinv0_1 = grad2(phiinv0,dx)\n",
    "    phiinv1_0,phiinv1_1 = grad2(phiinv1,dx)\n",
    "    detjac = phiinv0_0*phiinv1_1 - phiinv0_1*phiinv1_0\n",
    "    \n",
    "    # get the lambda for this time\n",
    "    lambda_ = interp2(x0,x1,lambda1,phiinv0,phiinv1)*detjac\n",
    "    \n",
    "    # set up the gradient\n",
    "    grad0 = -lambda_*I_0\n",
    "    grad1 = -lambda_*I_1\n",
    "    \n",
    "    # smooth it\n",
    "    grad0 = tf.real(tf.ifft2d(tf.fft2d(tf.cast(grad0,tf.complex64))*Khattf))\n",
    "    grad1 = tf.real(tf.ifft2d(tf.fft2d(tf.cast(grad1,tf.complex64))*Khattf))\n",
    "    \n",
    "    # add the regularization\n",
    "    grad0 = grad0 + v0\n",
    "    grad1 = grad1 + v1\n",
    "    \n",
    "    # and calculate the new v\n",
    "    vt0new_.append(v0 - epsilonph*grad0)\n",
    "    vt1new_.append(v1 - epsilonph*grad1)\n",
    "    \n",
    "vt0new = tf.stack(vt0new_[::-1],axis=2)\n",
    "vt1new = tf.stack(vt1new_[::-1],axis=2)\n",
    "\n",
    "\n",
    "step = tf.group(\n",
    "  vt0.assign(vt0new),\n",
    "  vt1.assign(vt1new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "EMall = []\n",
    "ERall = []\n",
    "Eall = []\n",
    "f,ax = plt.subplots(2,2)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(niter):\n",
    "        # take a step of gradient descent\n",
    "        step.run({epsilonph:epsilon})\n",
    "        \n",
    "        Idnp = It[-1].eval()\n",
    "        ax[0][0].imshow(Idnp,cmap='gray',aspect='equal',interpolation='none')\n",
    "        ax[0][0].set_title('deformed image, iter {}'.format(i))\n",
    "        lambda1np = lambda1.eval()\n",
    "        ax[0][1].imshow(lambda1np,cmap='gray',aspect='equal',interpolation='none')\n",
    "        ax[0][1].set_title('error')\n",
    "        EMall.append(EM.eval())\n",
    "        ERall.append(ER.eval())\n",
    "        Eall.append(E.eval())\n",
    "        ax[1][0].cla()\n",
    "        ax[1][0].plot(list(zip(Eall,EMall,ERall)))\n",
    "        xlim = ax[1][0].get_xlim()\n",
    "        ylim = ax[1][0].get_ylim()\n",
    "        ax[1][0].set_aspect((xlim[1]-xlim[0])/(ylim[1]-ylim[0]))\n",
    "        \n",
    "        f.canvas.draw()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
